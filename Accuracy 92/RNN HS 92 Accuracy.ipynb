{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Apply RNN Algorithm on Dataset\n",
    "\n",
    "#  To Classify the Speech as Hate or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Dataset with Display of 4 Values\n",
    "\n",
    "# 1000 Instances in labeled dataset\n",
    "\n",
    "# df DataFrame is a 2-dimensional labeled data structure with\n",
    "# columns of potentially different types.\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variables to X (label : Sentence), Y (label : positive or negative)\n",
    "\n",
    "x=df['tweet']\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model_selection is a method for setting a blueprint to \n",
    "analyze data and then using it to measure new data. \n",
    "Selecting a proper model allows you to generate accurate \n",
    "results when making a prediction. To do that, you need to train\n",
    "your model by using a specific dataset. \n",
    "Then, you test the model against another dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spilt data in Train & Test variables 20% train and 80% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:  (25569,)\n",
      "shape of X_test:  (6393,)\n",
      "shape of y_train:  (25569,)\n",
      "shape of y_test:  (6393,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X_train: \",X_train.shape)\n",
    "print(\"shape of X_test: \",X_test.shape)\n",
    "\n",
    "print(\"shape of y_train: \",y_train.shape)\n",
    "print(\"shape of y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " @user camping tomorrow @user @user @user @user @user @user @user dannyâ¦\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Print Train Data : Sentence with Comment LAbel(negative 0/ Postive 1)\n",
    "\n",
    "print(X_train[6]) \n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the Tokenizer class : create a word-to-index dictionary. In the word-to-index dictionary,\n",
    "# \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Top 1000 most frequent words\n",
    "tokenizer = Tokenizer(num_words=1000,lower=True)\n",
    "# Fitting Data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "# Sequencing the textual data (Converting into number)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360, 427]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[6]) \n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 12  89  48  20 281 281  89   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences \n",
    "# This library is out of support for new versions (Remember)\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100  #We set the maximum size of each list to 100.\n",
    "\n",
    "# pad_sequences is used to ensure that all sequences in a list have the same length.\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "##checking dataset locations\n",
    "print(X_train[3, :]) #the resulting feature vector contains mostly zeros, since you have a fairly short sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 2)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 2\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0])\n",
    "#print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 100, 1)\n",
      "(6393, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,SimpleRNN\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# (samples, timesteps, features)\n",
    "# (batch_size, timesteps, input_dim)\n",
    "\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "print(X_train.shape)  #(750, 100, 1)\n",
    "\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_test.shape)\n",
    "\n",
    "# Algo Requires 3d Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes=2\n",
    "\n",
    "def vanilla_rnn():\n",
    "    model = Sequential()\n",
    "    #model.add(SimpleRNN(50 neurons, input_shape = (X_train.shape[1], X_train.shape[2],), return_sequences = False))\n",
    "    model.add(SimpleRNN(50, input_shape = (maxlen,1), return_sequences = False))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax')) # softmax converts vector of no. into vector of prob.\n",
    "    # Calculate Prob of both Classes and class higher prob sentence \n",
    "    # will belong to that class\n",
    "    model.summary()\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy']) # Calculates how often predictions equal labels.\n",
    "\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (None, 50)                2600      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,702\n",
      "Trainable params: 2,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenevo\\AppData\\Local\\Temp\\ipykernel_9672\\2998331466.py:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = vanilla_rnn, epochs = 2, batch_size = 50)\n",
      "C:\\Users\\lenevo\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 7s 12ms/step - loss: 0.2641 - accuracy: 0.9267\n",
      "Epoch 2/2\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.2565 - accuracy: 0.9293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3f2d123a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# An epoch means training the neural\n",
    "# network with all the training data for one cycle\n",
    "model = KerasClassifier(build_fn = vanilla_rnn, epochs = 2, batch_size = 50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 5ms/step\n",
      "Percentage :  93.21132488659471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_ = np.argmax(y_test, axis = 1)\n",
    "\n",
    "# Accuracy predition\n",
    "\n",
    "print(\"Percentage : \", 100*accuracy_score(y_pred, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model on New input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "[0]\n",
      "Speech is Hate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a= ['good ']\n",
    "a = tokenizer.texts_to_sequences(a)\n",
    "a=np.array(a)\n",
    "# Preparing data to send to model and formating\n",
    "# it according to model\n",
    "a = pad_sequences(a, padding='post', maxlen=maxlen)\n",
    "\n",
    "a = a.reshape((a.shape[0], a.shape[1], 1))\n",
    "print(a.shape)\n",
    "\n",
    "prediction = model.predict(np.array(a))\n",
    "print(prediction) \n",
    "type(prediction)\n",
    "\n",
    "if prediction == [0]:\n",
    "    # 1 means speech is Hate\n",
    "    print(\"Speech is Hate\")\n",
    "\n",
    "if prediction == [1]:\n",
    "    # 0 means speech is Not Hate \n",
    "    print(\"Speech is Not Hate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
