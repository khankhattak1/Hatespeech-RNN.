{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Apply RNN Algorithm on Dataset\n",
    "\n",
    "#  To Classify the Speech as Hate or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading Dataset with Display of 4 Values\n",
    "\n",
    "# 1000 Instances in labeled dataset\n",
    "\n",
    "# df DataFrame is a 2-dimensional labeled data structure with\n",
    "# columns of potentially different types.\n",
    "\n",
    "# In TRAIN.CSV 0 is not HATE, 1 is HATE\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "#df = df.drop(df[(df.label == 0)].index)\n",
    "\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use variables to X (label : Sentence), Y (label : positive or negative)\n",
    "\n",
    "x=df['tweet']\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model_selection is a method for setting a blueprint to \n",
    "analyze data and then using it to measure new data. \n",
    "Selecting a proper model allows you to generate accurate \n",
    "results when making a prediction. To do that, you need to train\n",
    "your model by using a specific dataset. \n",
    "Then, you test the model against another dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spilt data in Train & Test variables 20% train and 80% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train:  (25569,)\n",
      "shape of X_test:  (6393,)\n",
      "shape of y_train:  (25569,)\n",
      "shape of y_test:  (6393,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X_train: \",X_train.shape)\n",
    "print(\"shape of X_test: \",X_test.shape)\n",
    "\n",
    "print(\"shape of y_train: \",y_train.shape)\n",
    "print(\"shape of y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " â #ireland consumer price index (mom) climbed from previous 0.2% to 0.5% in may   #blog #silver #gold #forex\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Print Train Data : Sentence with Comment LAbel(negative 0/ Postive 1)\n",
    "\n",
    "print(X_train[10]) \n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the Tokenizer class : create a word-to-index dictionary. In the word-to-index dictionary,\n",
    "# \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Top 1000 most frequent words\n",
    "tokenizer = Tokenizer(num_words=1000,lower=True)\n",
    "# Fitting Data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "\n",
    "# Sequencing the textual data (Converting into number)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[216, 9, 2, 99, 5, 29, 34, 92, 11, 35, 269, 265, 51, 426, 214]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[10]) \n",
    "print(y_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1  89  24  61 139 403   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# from keras.preprocessing.sequence import pad_sequences \n",
    "# This library is out of support for new versions (Remember)\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = 100  #We set the maximum size of each list to 100.\n",
    "\n",
    "# pad_sequences is used to ensure that all sequences in a list have the same length.\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "##checking dataset locations\n",
    "print(X_train[3, :]) #the resulting feature vector contains mostly zeros, since you have a fairly short sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 2)\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 2\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0])\n",
    "#print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25569, 100, 1)\n",
      "(6393, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,SimpleRNN\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# (samples, timesteps, features)\n",
    "# (batch_size, timesteps, input_dim)\n",
    "\n",
    "X_train = np.array(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "print(X_train.shape)  #(750, 100, 1)\n",
    "\n",
    "X_test = np.array(X_test).reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print(X_test.shape)\n",
    "\n",
    "# Algo Requires 3d Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes=2\n",
    "\n",
    "def vanilla_rnn():\n",
    "    model = Sequential()\n",
    "    #model.add(SimpleRNN(50 neurons, input_shape = (X_train.shape[1], X_train.shape[2],), return_sequences = False))\n",
    "    model.add(SimpleRNN(50, input_shape = (maxlen,1), return_sequences = False))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax')) # softmax converts vector of no. into vector of prob.\n",
    "    # Calculate Prob of both Classes and class higher prob sentence \n",
    "    # will belong to that class\n",
    "    model.summary()\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy']) # Calculates how often predictions equal labels.\n",
    "\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_18 (SimpleRNN)   (None, 50)                2600      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 102       \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,702\n",
      "Trainable params: 2,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenevo\\AppData\\Local\\Temp\\ipykernel_9672\\976912205.py:5: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = vanilla_rnn, epochs = 5, batch_size = 50)\n",
      "C:\\Users\\lenevo\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 7s 12ms/step - loss: 0.2991 - accuracy: 0.9070\n",
      "Epoch 2/5\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.2553 - accuracy: 0.9296\n",
      "Epoch 3/5\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.2557 - accuracy: 0.9296\n",
      "Epoch 4/5\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.2556 - accuracy: 0.9296\n",
      "Epoch 5/5\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.2557 - accuracy: 0.9296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b39d6acc10>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# An epoch means training the neural\n",
    "# network with all the training data for one cycle\n",
    "model = KerasClassifier(build_fn = vanilla_rnn, epochs = 5, batch_size = 50)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 5ms/step\n",
      "Percentage :  93.10183012670107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "y_test_ = np.argmax(y_test, axis = 1)\n",
    "\n",
    "# Accuracy predition\n",
    "\n",
    "print(\"Percentage : \", 100*accuracy_score(y_pred, y_test_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model on New input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "[0]\n",
      "NotHate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = [\"when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.\"]\n",
    "a = tokenizer.texts_to_sequences(a)\n",
    "a = np.array(a)\n",
    "# Preparing data to send to model and formating\n",
    "# it according to model\n",
    "a = pad_sequences(a, padding='post', maxlen=maxlen)\n",
    "\n",
    "a = a.reshape((a.shape[0], a.shape[1], 1))\n",
    "print(a.shape)\n",
    "\n",
    "prediction = model.predict(np.array(a))\n",
    "print(prediction) \n",
    "type(prediction)\n",
    "\n",
    "if prediction == [0]:\n",
    "    print('NotHate')\n",
    "\n",
    "if prediction == [1]:\n",
    "    print('Hate')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
